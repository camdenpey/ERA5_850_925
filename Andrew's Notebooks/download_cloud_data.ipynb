{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1f6371c-8eec-4cd3-9758-4fbd4c12e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "#select and name the lat/lon locations you want the data for\n",
    "COORDS = {\n",
    "        \"Springfield\":[37.235,  -93.402],  \n",
    "        \"Joplin\":[37.156, -94.503],  \n",
    "        \"West Plains\":[36.879, -91.905],   \n",
    "        \"Vichy\":[38.131, -91.764] \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc29b577-c1f2-49fe-8b6e-20c51b0d02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your year and month in YYYY and M format (i.e. 1990, 1)\n",
    "#finished\n",
    "selected_year = 2011\n",
    "selected_month = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4144531-2e86-427d-9459-cf1a565c1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert your chosen month to strings for the downloader to parse and to\n",
    "#name the file and whatever \n",
    "\n",
    "import datetime\n",
    "#remove the 0 after the f for months 10,11, and 12, add back for single digits\n",
    "input = f'{selected_month}/{selected_year}'\n",
    "my_date = datetime.datetime.strptime(input, \"%m/%Y\")\n",
    "convert_my_date = datetime.datetime.strftime(my_date, '%Y_%B')\n",
    "\n",
    "#add a zero in front of the month number so the downloader takes it\n",
    "month_conversion = f'{selected_month}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bff15a4a-086c-46fd-b1f4-14aa0e69ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#could also add a function to add, adjust, change any of the following:\n",
    "#dataset used, variables pulled, pressure levels, or format of output\n",
    "\n",
    "#could also add a dictionary for pressure specifically if wanting to add that to\n",
    "#the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b8765f0-1808-4804-a096-aefa3c71031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 12:42:17,263 INFO Welcome to the CDS\n",
      "2024-07-23 12:42:17,263 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-07-23 12:42:17,612 INFO Request is queued\n",
      "2024-07-23 12:42:18,782 INFO Request is running\n",
      "2024-07-23 12:44:12,603 INFO Request is completed\n",
      "2024-07-23 12:44:12,603 INFO Downloading https://download-0018.copernicus-climate.eu/cache-compute-0018/cache/data3/adaptor.mars.internal-1721756642.5246387-9566-8-34c6ad92-1adb-4cda-82c6-e828f0096ee3.nc to Springfield_2011_January_clouds.nc (6.5K)\n",
      "2024-07-23 12:44:13,265 INFO Download rate 9.9K/s                                                                      \n",
      "2024-07-23 12:44:13,593 INFO Welcome to the CDS\n",
      "2024-07-23 12:44:13,593 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-07-23 12:44:13,913 INFO Request is queued\n",
      "2024-07-23 12:44:16,745 INFO Request is running\n",
      "2024-07-23 12:46:08,913 INFO Request is completed\n",
      "2024-07-23 12:46:08,913 INFO Downloading https://download-0018.copernicus-climate.eu/cache-compute-0018/cache/data3/adaptor.mars.internal-1721756753.7997103-21272-9-695fda23-cbf9-44f4-b0b6-8907da3d1d4e.nc to Joplin_2011_January_clouds.nc (6.5K)\n",
      "2024-07-23 12:46:09,582 INFO Download rate 9.9K/s                                                                      \n",
      "2024-07-23 12:46:09,913 INFO Welcome to the CDS\n",
      "2024-07-23 12:46:09,913 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-07-23 12:46:10,443 INFO Request is queued\n",
      "2024-07-23 12:46:43,773 INFO Request is running\n",
      "2024-07-23 12:49:03,270 INFO Request is completed\n",
      "2024-07-23 12:49:03,272 INFO Downloading https://download-0017.copernicus-climate.eu/cache-compute-0017/cache/data4/adaptor.mars.internal-1721756891.7743301-20320-6-924b74f4-a04b-4e88-b160-eafe3597959e.nc to West Plains_2011_January_clouds.nc (6.5K)\n",
      "2024-07-23 12:49:04,664 INFO Download rate 4.7K/s                                                                      \n",
      "2024-07-23 12:49:05,034 INFO Welcome to the CDS\n",
      "2024-07-23 12:49:05,044 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-07-23 12:49:05,354 INFO Request is queued\n",
      "2024-07-23 12:49:06,526 INFO Request is running\n",
      "2024-07-23 12:51:00,350 INFO Request is completed\n",
      "2024-07-23 12:51:00,351 INFO Downloading https://download-0017.copernicus-climate.eu/cache-compute-0017/cache/data4/adaptor.mars.internal-1721757041.1261256-20135-9-b3b1208f-05b9-46f2-87be-7d0eed3d97b4.nc to Vichy_2011_January_clouds.nc (6.5K)\n",
      "2024-07-23 12:51:00,992 INFO Download rate 10.2K/s                                                                     \n"
     ]
    }
   ],
   "source": [
    "#retrieve the data\n",
    "c = cdsapi.Client()\n",
    "    \n",
    "for station in COORDS:\n",
    "  station_point_coord = COORDS[station]*2 # duplicate it\n",
    "  c.retrieve(\n",
    "      'reanalysis-era5-single-levels',\n",
    "      {\n",
    "          'product_type': 'reanalysis',\n",
    "          'variable': ['cloud_base_height','total_cloud_cover','medium_cloud_cover','high_cloud_cover',],\n",
    "          'year': f'{selected_year}',\n",
    "          'month': f'{month_conversion}',\n",
    "          'day': [\n",
    "              '01', '02', '03',\n",
    "              '04', '05', '06',\n",
    "              '07', '08', '09',\n",
    "              '10', '11', '12',\n",
    "              '13', '14', '15',\n",
    "              '16', '17', '18',\n",
    "              '19', '20', '21',\n",
    "              '22', '23', '24',\n",
    "              '25', '26', '27',\n",
    "              '28', '29', '30',\n",
    "              '31',\n",
    "          ],\n",
    "          'time': ['0:00', '12:00','13:00','14:00','15:00','16:00','17:00','18:00','19:00','20:00','21:00','22:00','23:00',],\n",
    "          'area': station_point_coord,\n",
    "          'format': 'netcdf',\n",
    "      },\n",
    "      f'{station}_{convert_my_date}_clouds.nc')\n",
    "\n",
    "#you'll know it ran correctly if a pink box appears underneath and the status says queued\n",
    "#and the output will be available in the active directory if it gives you a download rate\n",
    "#after a link showing the proper file name\n",
    "\n",
    "#...if that makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6519af77-c608-4ad0-a7f8-ec8b8698fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_storage_directory should be the location you're actively running\n",
    "local_storage_directory = 'C:/Users/sgfsad/netcdf/'\n",
    "\n",
    "#netcdf_dir should be where the netcdf is saved to\n",
    "#uncomment (delete the #) before ' + 'directory/' if you don't have a different\n",
    "#folder for the netcdf rather than your working directory\n",
    "netcdf_dir = local_storage_directory #+ 'netcdf/'\n",
    "\n",
    "#csv_dir is where the converted file should be saved to, which is the shared drive\n",
    "csv_dir = 'S:/Science_and_Research/ERA5_Reanalysis_1990-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf08d81d-ca50-40d6-9161-64d0932baeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cf97069a-a47e-42e0-8b65-83810a4cadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the file name in quote by the file name of the netcdf file (.nc) you want to convert to csv\n",
    "\n",
    "for station in COORDS: \n",
    "    #Set variables names for the input file.nc (netcdf_file_in) and the output file.csv (`csv_file_out`)\n",
    "    netcdf_file_name = f'{station}_{convert_my_date}_clouds.nc'\n",
    "    netcdf_file_in = netcdf_dir + netcdf_file_name\n",
    "    csv_file_out = csv_dir + netcdf_file_name[:-3] + '.csv'\n",
    "    #convert\n",
    "    ds = xr.open_dataset(netcdf_file_in)\n",
    "    df = ds.to_dataframe()\n",
    "    df.to_csv(csv_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f93403-22e8-4f48-b091-b2f70fc159f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc822cd-ff2d-48d0-bd88-8097afed7331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
