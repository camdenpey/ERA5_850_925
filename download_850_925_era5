{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd6b390-2e2d-4719-a926-5329815bc952",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "prerequisite packages: cdsapi, xarray, netcdf4, dask, scipy, bottleneck, numpy, pandas, zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d501ea7-901c-4d59-9564-7d7c4d35e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "#select and name the lat/lon locations you want the data for\n",
    "COORDS = {\n",
    "        \"Springfield\":[37.235,  -93.402],  \n",
    "        \"Joplin\":[37.156, -94.503],  \n",
    "        \"West Plains\":[36.879, -91.905],   \n",
    "        \"Vichy\":[38.131, -91.764] \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8be3ce70-9a66-4d06-bc19-6eaf31fa6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your year and month in YYYY and M format (i.e. 1990, 1)\n",
    "\n",
    "selected_year = 2012\n",
    "selected_month = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9066074b-b5a6-46f0-85b1-bf3223116a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert your chosen month to strings for the downloader to parse and to\n",
    "#name the file and whatever \n",
    "\n",
    "import datetime\n",
    "\n",
    "input = f'0{selected_month}/{selected_year}'\n",
    "my_date = datetime.datetime.strptime(input, \"%m/%Y\")\n",
    "convert_my_date = datetime.datetime.strftime(my_date, '%Y_%B')\n",
    "\n",
    "#add a zero in front of the month number so the downloader takes it\n",
    "month_conversion = f'0{selected_month}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "745f5c7b-1d30-481e-9c72-13d897de8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#could also add a function to add, adjust, change any of the following:\n",
    "#dataset used, variables pulled, pressure levels, or format of output\n",
    "\n",
    "#could also add a dictionary for pressure specifically if wanting to add that to\n",
    "#the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c000322-de2d-40c0-a6df-8ed973cb9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 04:14:19,244 INFO Welcome to the CDS\n",
      "2024-06-05 04:14:19,245 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels\n",
      "2024-06-05 04:14:19,466 INFO Request is completed\n",
      "2024-06-05 04:14:19,467 INFO Downloading https://download-0004-clone.copernicus-climate.eu/cache-compute-0004/cache/data8/adaptor.mars.internal-1717577916.618546-15556-15-dc8ebd8a-efe2-4907-baef-41b10ae4bc6b.nc to Springfield_2012_January.nc (1.5K)\n",
      "2024-06-05 04:14:20,764 INFO Download rate 1.1K/s                                                                      \n",
      "2024-06-05 04:14:21,076 INFO Welcome to the CDS\n",
      "2024-06-05 04:14:21,077 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels\n",
      "2024-06-05 04:14:21,277 INFO Request is queued\n",
      "2024-06-05 04:14:22,442 INFO Request is running\n",
      "2024-06-05 04:14:30,039 INFO Request is completed\n",
      "2024-06-05 04:14:30,040 INFO Downloading https://download-0005-clone.copernicus-climate.eu/cache-compute-0005/cache/data7/adaptor.mars.internal-1717578867.1864586-4885-2-6e8f85c1-3360-4f5b-9da7-d1116580feef.nc to Joplin_2012_January.nc (1.5K)\n",
      "2024-06-05 04:14:32,037 INFO Download rate 753.8/s                                                                     \n",
      "2024-06-05 04:14:32,350 INFO Welcome to the CDS\n",
      "2024-06-05 04:14:32,351 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels\n",
      "2024-06-05 04:14:32,562 INFO Request is queued\n",
      "2024-06-05 04:14:33,721 INFO Request is running\n",
      "2024-06-05 04:14:35,379 INFO Request is completed\n",
      "2024-06-05 04:14:35,380 INFO Downloading https://download-0012-clone.copernicus-climate.eu/cache-compute-0012/cache/data5/adaptor.mars.internal-1717578873.692793-15371-17-5eb74e6e-18f7-48d0-bfc8-54c070635368.nc to West Plains_2012_January.nc (1.5K)\n",
      "2024-06-05 04:14:37,081 INFO Download rate 884.6/s                                                                     \n",
      "2024-06-05 04:14:37,395 INFO Welcome to the CDS\n",
      "2024-06-05 04:14:37,396 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels\n",
      "2024-06-05 04:14:37,582 INFO Request is queued\n",
      "2024-06-05 04:14:38,739 INFO Request is running\n",
      "2024-06-05 04:14:42,803 INFO Request is completed\n",
      "2024-06-05 04:14:42,804 INFO Downloading https://download-0011-clone.copernicus-climate.eu/cache-compute-0011/cache/data3/adaptor.mars.internal-1717578880.940311-4315-15-f6411d7b-4953-417d-b7ad-6faaa5d9e27a.nc to Vichy_2012_January.nc (1.5K)\n",
      "2024-06-05 04:14:44,453 INFO Download rate 910.3/s                                                                     \n"
     ]
    }
   ],
   "source": [
    "#retrieve the data\n",
    "c = cdsapi.Client()\n",
    "    \n",
    "for station in COORDS:\n",
    "  station_point_coord = COORDS[station]*2 # duplicate it\n",
    "  c.retrieve(\n",
    "      'reanalysis-era5-pressure-levels',\n",
    "      {\n",
    "          'product_type': 'reanalysis',\n",
    "          'variable': 'temperature',\n",
    "          'pressure_level': [\n",
    "            '850', '925',\n",
    "        ],\n",
    "          'year': f'{selected_year}',\n",
    "          'month': f'{month_conversion}',\n",
    "          'day': [\n",
    "              '01', '02', '03',\n",
    "              '04', '05', '06',\n",
    "              '07', '08', '09',\n",
    "              '10', '11', '12',\n",
    "              '13', '14', '15',\n",
    "              '16', '17', '18',\n",
    "              '19', '20', '21',\n",
    "              '22', '23', '24',\n",
    "              '25', '26', '27',\n",
    "              '28', '29', '30',\n",
    "              '31',\n",
    "          ],\n",
    "          'time': '12:00',\n",
    "          'area': station_point_coord,\n",
    "          'format': 'netcdf',\n",
    "      },\n",
    "      f'{station}_{convert_my_date}.nc')\n",
    "\n",
    "#you'll know it ran correctly if a pink box appears underneath and the status says queued\n",
    "#and the output will be available in the active directory if it gives you a download rate\n",
    "#after a link showing the proper file name\n",
    "\n",
    "#...if that makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d40ca5-1865-4ea8-a4c5-b29448c38b6e",
   "metadata": {},
   "source": [
    "##### Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a356d1f-96fc-4d38-8d95-c4821bc702d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_storage_directory should be the location you're actively running\n",
    "local_storage_directory = 'C:/Users/peyton.camden/Notebooks/'\n",
    "\n",
    "#netcdf_dir should be where the netcdf is saved to\n",
    "#uncomment (delete the #) before ' + 'directory/' if you don't have a different\n",
    "#folder for the netcdf rather than your working directory\n",
    "netcdf_dir = local_storage_directory #+ 'netcdf/'\n",
    "\n",
    "#csv_dir is where the converted file should be saved to, which is the shared drive\n",
    "csv_dir = 'S:/Science_and_Research/ERA5_Reanalysis_1990-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f008a25-0620-4ebc-b383-08fbef307703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34ea2410-24cf-46ad-81d0-9e50ff4419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the file name in quote by the file name of the netcdf file (.nc) you want to convert to csv\n",
    "\n",
    "for station in COORDS: \n",
    "    #Set variables names for the input file.nc (netcdf_file_in) and the output file.csv (`csv_file_out`)\n",
    "    netcdf_file_name = f'{station}_{convert_my_date}.nc'\n",
    "    netcdf_file_in = netcdf_dir + netcdf_file_name\n",
    "    csv_file_out = csv_dir + netcdf_file_name[:-3] + '.csv'\n",
    "    #convert\n",
    "    ds = xr.open_dataset(netcdf_file_in)\n",
    "    df = ds.to_dataframe()\n",
    "    df.to_csv(csv_file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd40a08-a65f-485c-842c-a959517d0076",
   "metadata": {},
   "source": [
    "# Your converted CSV file should be in the S drive folder! Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c110161-071b-44e3-aaba-533a6c20fa69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
